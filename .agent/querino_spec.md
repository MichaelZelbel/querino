# Querino

# 

Querino is a platform where people **discover, organize, refine, and publish AI prompts, skills, workflows, and other LLM artefacts**. It blends a **public prompt discovery experience** with a **private creator studio**, so users can both explore high-quality prompts and build their own prompt libraries in one place.

On the **public homepage**, visitors see curated, highly-rated prompts ranked with an Amazon-style star system based on community reviews. Each prompt can be copied instantly for use in any LLM.

When users sign up, Querino becomes a **personal AI creation dashboard**. They can pin their favorite prompts, create and version their own, improve them using AI-powered tools, publish prompts to the community, and manage their library of prompts, Claude skills, and workflows in one unified interface. They also have access to an integrated **LLM chat assistant** that helps them brainstorm, refine, and debug prompts directly inside the dashboard.

Querino supports a **free and premium tier**. Free users can browse, rate, and save prompts, while premium users unlock advanced tooling such as the prompt-improvement suite, in-dashboard LLM chat, and the option to mirror their personal prompt library into GitHub for version control.

In short, Querino is both a **discovery engine for powerful prompts** and a **professional prompt-building environment**, giving every user a place to find, create, refine, and share the AI building blocks they rely on.

# Vision

Querino’s vision is to unify the entire lifecycle of prompt engineering — discovery, creation, refinement, and professional management — into a single, elegant workspace.  
 Users should be able to:

* **Discover** high-quality prompts validated by real community reviews

* **Create** personalized prompts through a guided wizard

* **Improve** prompts using AI-powered refinement tools

* **Manage** a clean, versioned library of prompts, skills, and workflows

* **Publish** their best work to the community

* **Learn** by chatting directly with an integrated LLM prompt coach

* **Mirror** their library to GitHub for professional version control (premium)

Querino aims to become the **default studio for AI prompt creation and curation**, helping users move from scattered experiments to a structured, high-performance workflow.

# Target Audience

Querino is built for people who work with AI regularly and struggle to keep their prompts organized, discover new high-quality prompting techniques, or improve their own prompt craft. Our main user groups are:

**• AI enthusiast creators and hobbyists**  
 People who use ChatGPT, Claude, or similar tools daily and want reliable prompts, better results, and a place to store their growing personal prompt library.

**• Indie hackers, solopreneurs, and SaaS builders**  
 They rely on prompts, assistants, workflows, and LLM skills to power their projects, but lack a centralized place to version, test, improve, and reuse them.

**• Developers & technical professionals exploring LLM tooling**  
 Especially those creating agents, workflows, or automation pipelines who need structured prompt management and optional GitHub sync.

**• Content creators, marketers, and writers**  
 They constantly look for high-quality prompts for ideation, writing, and optimization, and benefit from a curated, review-driven discovery experience.

**• Educators and prompt engineers**  
 They create many variations of learning prompts and need a workspace where they can test, maintain, and share them with students or teams.

**• Small teams working on AI-driven products**  
 Teams that want a shared prompt library and internal best-practices, plus tools for reviewing, improving, and publishing prompts.

# Problems Solved

People who use AI regularly accumulate a growing number of prompts, skills, and workflows scattered across documents, chats, screenshots, bookmarks, and random notes. Their prompt library becomes **disorganized, unversioned, and hard to improve**, causing repeated work and inconsistent results.

At the same time, discovering *good* prompts online is unreliable. Most prompt collections surface low-quality, untested content with no real user validation. Users have no sense of what actually works, in what context, or why.

But an even deeper problem is this:  
 **Most serious AI users don’t actually want generic prompts.**  
 They need **custom, individualized prompts** tailored to their domain, product, workflow, tone, skills, and use cases. Those cannot simply be “looked up” in a library.

Querino solves the whole lifecycle of this pain:

* It offers a **high-quality discovery layer** where prompts are ranked by real user ratings (Amazon-style reviews).

* It gives users a **structured workspace** to store, version, and improve their own prompts, skills, and workflows.

* It includes **AI-powered improvement tools** so users can refine or debug a prompt with guidance.

* And most importantly, Querino provides a **prompt creation wizard**:  
   A guided flow that asks the user the right questions, understands their context, and generates a tailored, high-performance prompt that follows a proven framework for their chosen LLM.

For advanced users, Querino can even **mirror their prompt library to GitHub** so they treat prompts like code: versioned, reviewable, and maintainable.

In short:  
 People lack a reliable way to **discover high-quality prompts**, and a guided system to **create professional, individualized prompts** — and they struggle to manage, refine, and version everything they build. Querino solves all of that in one place.

# The Solution

Querino brings together three capabilities that currently live in completely separate worlds:  
 **(1) discovery, (2) creation, and (3) professional management** of prompts and AI artefacts.

### **1\. Discovery: A trusted marketplace of proven prompts**

Querino presents users with a curated home feed of **community-rated prompts**, sorted by real performance and user satisfaction.  
 Instead of wading through random lists, people see what *actually works*, backed by detailed reviews and transparent context.

This solves the “I need something effective right now” problem.

---

### **2\. Creation: A guided wizard that builds personalized prompts**

Most users need prompts tailored to their exact domain, workflow, tone, and tools. Querino includes an interactive **Prompt Creation Wizard** that asks smart, context-aware questions and produces a refined, individualized prompt built on proven frameworks for their LLM of choice.

This solves the “I need a great prompt but I don’t know how to craft one” problem.

---

### **3\. Management: A private, powerful prompt workspace**

Logged-in users get a dashboard that acts like a professional studio for their AI-building blocks. They can:

* Create, version, and refine prompts, skills, workflows

* Pin important prompts to their dashboard

* Improve prompts using built-in AI tools

* Publish selected prompts to the community

* Mirror everything to GitHub for version control (premium)

This solves the “my prompts are everywhere and I can’t maintain them” problem.

---

### **4\. Learning: A built-in LLM assistant for prompt coaching**

Within the dashboard, users can chat with an integrated LLM assistant that helps them:

* Understand why a prompt isn’t working

* Improve clarity and structure

* Adapt it to new models

* Follow best-practice frameworks

This solves the “I want to get better at prompting, but I need guidance” problem.

---

### **The Value Querino Creates**

Querino transforms prompt usage from a scattered, inconsistent habit into a **structured, professional workflow**. Users gain:

* Faster access to high-performing prompts

* Higher-quality outputs from their LLMs

* A stable, organized repository of their own AI tools

* The ability to collaborate, share, and learn from others

* A long-term asset: their personalized prompt library

Querino becomes the place where people **discover, create, improve, and manage every prompting tool they rely on** — all under one roof.

# Look and Feel (UX)

Querino should feel like a **calm, intelligent workspace**—a place where AI builders come to think clearly, organize their ideas, and discover new prompting techniques without distraction.

### **Overall Vibe**

* **Clean, modern, and professional**, with subtle personality

* A mood similar to high-end developer tools (Linear, Vercel Dashboard) blended with the polish of consumer-facing discovery apps (Notion, Read.cv, PromptLoft)

* A balance of **warmth \+ precision**, expressing trust and creativity at the same time

Querino should feel like a tool used by someone smart — but welcoming enough that newcomers don’t feel lost.

---

### **Homepage Experience**

For non-logged-in users:

* A **beautiful, curated gallery of prompts**, each presented as a card with a clear rating, title, short description, and copy button

* The mood: *“Wow, this is a place where good prompts actually live.”*

* Interaction should feel light, elegant, scroll-friendly, and discovery-driven

This page should feel a bit like:

* **PromptLoft**, for its clean card-based layout

* **Product Hunt**, for presenting items in a way that feels alive and relevant

* **Amazon Reviews**, in how ratings look and feel

---

### **Dashboard Experience (for logged-in users)**

Querino’s dashboard should feel like a **personal command center**:

* A left sidebar for navigation (Library, Wizard, Reviews, GitHub, Settings)

* A spacious main area with cards for:

  * Pinned prompts

  * Recent prompts

  * “Improve Prompt” tools

  * “Create New Prompt” wizard

  * In-app LLM chat assistant

The tone should be:

* **Organized but not rigid**

* **Creative but not chaotic**

* **Powerful but not overwhelming**

Think:  
 *“I’m in my studio. Everything I need is here. I can work fast.”*

---

### **Visual Language**

* Clean, structured typography

* Lots of whitespace

* Friendly rounded corners

* Soft glows or gradients sparingly used

* A warm but modern palette (blues, violets, neutrals, maybe a soft neon accent)

* Cards and sections feel weightless and modular, inspired by:

  * **Notion** (calm simplicity)

  * **Linear** (hyper-clean UI)

  * **Vercel** (minimalistic, confident design)

  * **Superhuman** (speed-focused interaction cues)

---

### **Interaction Patterns**

* Everything should be **fast, frictionless, and enjoyable**

* Users can:

  * Pin prompts with a single click

  * Copy any prompt cleanly

  * Drag cards to rearrange their dashboard (future feature)

  * Open prompt detail views in sliding panels or modal drawers

  * Use the Prompt Wizard as a guided flow (multi-step, smooth transitions)

Querino should always communicate this feeling:

“You’re creating something valuable — let’s make this feel effortless.”

---

### **AI Assistant UX**

* Built into the dashboard as a friendly, supportive prompt coach

* Conversation appears in a side panel or a bottom drawer

* Always contextual: it understands your prompt library and goals

* The tone: *expert, reassuring, and slightly playful — never robotic*

---

### **Mobile**

* Fully responsive

* Prompt cards stack beautifully

* Dashboard collapses sidebar into a floating icon

* Wizard becomes swipe-friendly

---

### **Overall Feeling for the User**

Querino should give users a sense of:

* **Mastery** over their prompt library

* **Inspiration** from the discovery feed

* **Clarity** thanks to a structured interface

* **Momentum** toward building better prompts

* **Confidence** that they have a tool built for serious AI work

In short: Querino should feel like a **creative studio for AI prompting**, not just a utility.

# Personas

### Aisha, The AI Artisan

#### Demographics

* Age: 28-38  
* Income: $70k-120k  
* Location: Major Tech Hub Cities (e.g., Austin, Seattle, Berlin)  
* Occupation: Freelance AI Content Creator, Digital Marketer, Mid-level UX Designer leveraging AI

#### Key Insights

Tech Savviness:High

Adoption Likelihood:90%

#### Pain Points

Struggles to organize a growing collection of prompts across various documents and chat histories.Time-consuming to find high-quality, effective prompts for specific creative tasks.Difficulty in systematically refining and versioning her own prompts to improve output quality.Feels isolated in her prompt crafting journey, lacking a community to share and learn from.

### Ben, The Prompt Engineer Apprentice

#### Demographics

* Age: 22-30  
* Income: $50k-80k  
* Location: University Towns, Entry-level Tech Hubs  
* Occupation: Junior Developer, Data Analyst, AI/ML Student, Tech Enthusiast Hobbyist

#### Key Insights

Tech Savviness:High

Adoption Likelihood:85%

#### Pain Points

Overwhelmed by the sheer volume of information on prompt engineering; struggles to find reliable resources.Lacks structured tools to experiment with and learn prompt refinement techniques.Finds it hard to track changes and improvements made to prompts over time.Unsure how to effectively leverage AI for brainstorming and debugging his own prompts.

### Chloe, The Corporate Innovator

#### Demographics

* Age: 35-45  
* Income: $90k-150k  
* Location: Global Business Centers (e.g., New York, London, Singapore)  
* Occupation: Product Manager, Business Analyst, Innovation Lead in a large enterprise

#### Key Insights

Tech Savviness:Medium-High

Adoption Likelihood:75%

#### Pain Points

Struggles to standardize and share effective prompts across her team or department.Lacks a centralized repository for team-approved AI workflows and 'Claude skills'.Concerned about version control and maintaining a consistent library of prompts for internal use.Needs a secure way to manage and potentially mirror proprietary prompt libraries.

### David, The AI Power User

#### Demographics

* Age: 30-45  
* Income: $80k-130k  
* Location: Remote-first, Global  
* Occupation: Senior Software Engineer, AI Consultant, Technical Writer specializing in AI

#### Key Insights

Tech Savviness:Very High

Adoption Likelihood:88%

#### Pain Points

Manually managing a vast and complex personal library of prompts, often in text files or Notion.Desires advanced tools for prompt optimization and debugging that go beyond basic iteration.Needs seamless integration with version control systems for his prompt development.Seeks a platform that supports not just prompts, but also more complex AI artifacts like 'Claude skills' and workflows.

# UX Flows

### Public Prompt Discovery & Copy

High

#### Steps

* 1  
* Visitor lands on Querino homepage.  
* 2  
* Visitor browses curated, highly-rated prompts (e.g., by category, trending, search).  
* 3  
* Visitor views a specific prompt's details (description, reviews, star rating).  
* 4  
* Visitor clicks 'Copy Prompt' button.  
* 5  
* Prompt text is copied to clipboard, and a confirmation message is displayed.

#### Metrics

Completion Time:1-2 minutes

Drop-off Risk:10%

### Free User Sign-Up & Initial Exploration

High

#### Steps

* 1  
* Visitor encounters a 'Sign Up' call-to-action (e.g., after copying a prompt, or from navigation).  
* 2  
* Visitor clicks 'Sign Up' and is presented with registration form (email/password or social login).  
* 3  
* Visitor completes registration.  
* 4  
* User is redirected to their personal dashboard.  
* 5  
* User sees an onboarding tour or clear prompts to 'Pin Favorite Prompts' or 'Create New Prompt'.

#### Metrics

Completion Time:2-3 minutes

Drop-off Risk:25%

### Premium Feature Upgrade

Medium

#### Steps

* 1  
* Free user attempts to access a premium feature (e.g., 'Prompt Improvement Suite', 'In-Dashboard LLM Chat').  
* 2  
* User is presented with an upgrade modal or page.  
* 3  
* Upgrade modal/page clearly outlines premium benefits and pricing tiers.  
* 4  
* User selects a premium tier and proceeds to payment.  
* 5  
* User completes payment and gains access to premium features.

#### Metrics

Completion Time:3-5 minutes

Drop-off Risk:35%

### Prompt Creation & Publishing (Premium/Free)

High

#### Steps

* 1  
* Signed-in user navigates to 'Create New Prompt' in their dashboard.  
* 2  
* User enters prompt title, description, and the prompt text itself.  
* 3  
* User adds tags, categories, and other metadata.  
* 4  
* User saves the prompt (private by default).  
* 5  
* User optionally chooses to 'Publish to Community' (after review/moderation if applicable).

#### Metrics

Completion Time:5-10 minutes

Drop-off Risk:20%

### Prompt Refinement with AI Tools (Premium)

Medium

#### Steps

* 1  
* Premium user selects an existing prompt from their library.  
* 2  
* User clicks on 'Refine with AI' or similar button.  
* 3  
* User is presented with AI-powered tools (e.g., 'Improve Clarity', 'Expand Options', 'Debug').  
* 4  
* User applies a refinement tool.  
* 5  
* User reviews the AI-suggested changes and accepts or modifies them.  
* 6  
* User saves the refined prompt (potentially as a new version).

#### Metrics

Completion Time:3-7 minutes

Drop-off Risk:15%

### Organizing & Managing Prompt Library (Free/Premium)

High

#### Steps

* 1  
* Signed-in user navigates to 'My Library' or 'My Prompts'.  
* 2  
* User views a list of their saved/created prompts.  
* 3  
* User can filter, sort, or search their prompts.  
* 4  
* User can pin favorite prompts for quick access.  
* 5  
* User can edit, delete, or manage versions of their prompts.

#### Metrics

Completion Time:2-5 minutes

Drop-off Risk:10%

# Authentication

Querino supports three authentication methods: **Google**, **GitHub**, and **email \+ password**. Users may choose any of these during sign-up or sign-in. Accounts created via OAuth (Google or GitHub) automatically import the user’s display name and profile image, which is shown in the dashboard header and account menu. Users who register with email and password may upload their own profile image or continue using the default avatar. All authentication is handled through Supabase Auth, and all methods provide the same access to plans, features, and billing.

# GitHub Mirroring (Premium Feature)

Querino’s GitHub integration allows premium users (or administrators in a team workspace) to connect an existing GitHub repository and optionally specify a target folder within that repository. Querino will mirror its internal prompt structure into that folder.

Users may select:

* The repository (`username/repository`)

* The branch (default: `main`)

* The base folder path (e.g., `/querino`, `/ai/prompts`, `/libraries/marketing`, `/team/prompt-assets`)

Querino will create and maintain a structured hierarchy inside that folder, for example:

* `/prompts/{prompt_id}.md`

* `/versions/{prompt_id}/{version_number}.md`

* `/metadata/{prompt_id}.json`

When prompts are created, updated, or versioned in Querino, the corresponding files in the specified folder are updated and committed automatically. If the folder does not exist, Querino creates it. Users retain full ownership and control of the repository.

### **GitHub Sync – Commit and Push Metadata**

To support committing and pushing changes to GitHub, Querino should store minimal metadata about its last sync state and configuration. The GitHub repository itself remains the source of truth for full commit history; Querino only keeps what it needs to manage sync behaviour and status.

#### **Extended `github_sync` table**

**github\_sync**

* user\_id (uuid) — primary key; one configuration per user or team

* repo (text) — full name of the target repository, e.g. `username/project-repo`

* folder\_path (text) — folder inside the repo where Querino writes its files, e.g. `querino/` or `ai/prompts/`

* branch (text) — branch to sync with, typically `main` or `master`

* sync\_enabled (boolean) — toggle for automatic mirroring

* sync\_mode (text) — e.g. `direct_commit` or `pull_request`

* commit\_author\_name (text) — name to use for Querino commits

* commit\_author\_email (text) — email to use for Querino commits

* last\_synced\_at (timestamp) — time of last successful sync

* last\_synced\_commit\_sha (text) — SHA of the last commit created by Querino

* last\_sync\_status (text) — e.g. `success`, `failed`, `pending`

* last\_sync\_error (text) — optional error message or code from the last failed sync

### **Commit and Push Behaviour**

When a sync is triggered (either automatically or manually), Querino will:

1. Generate or update files under the configured `folder_path` on the configured `branch`.

2. Create a commit using `commit_author_name` and `commit_author_email`.

3. Push the commit directly if `sync_mode = direct_commit`, or open/update a pull request if `sync_mode = pull_request`.

4. Update `last_synced_at`, `last_synced_commit_sha`, and `last_sync_status`.

5. Populate `last_sync_error` only if the operation fails.

Querino does not need to store the full commit history; GitHub remains the authoritative system for commits and branches.

# Market Fit

### Revenue Projections

Year 1 ARR $250K

Year 3 ARR $2.5M

Year 5 ARR $10.0M

### Competition Analysis

#### Direct Competitors

* PromptBase  
* FlowGPT  
* PromptHero  
* Hugging Face (for models/datasets, less for prompts)

#### Competitive Advantages

* • Blended public discovery and private creation studio  
* • AI-powered prompt improvement tools  
* • Integrated LLM chat assistant for refinement and debugging  
* • GitHub mirroring for version control (premium feature)  
* • Unified interface for prompts, Claude skills, and workflows

# Compliance

1. GDPR compliance for EU users regarding personal data collection (e.g., email for sign-up, user-generated content, usage data).  
2. CCPA/CPRA compliance for California residents, including 'Do Not Sell/Share My Personal Information' rights and data access/deletion requests.  
3. CCPA: Transparent privacy policy detailing data collection, usage, storage, and sharing practices, including for AI-powered tools.  
4. CCPA: Obtain explicit consent for non-essential cookies and data processing activities, especially for tracking user behavior.  
5. GDPR: Implement robust data security measures (encryption, access controls) to protect user-generated prompts, personal libraries, and account information.  
6. GDPR: Transparency regarding the use of AI-powered tools (e.g., prompt-improvement suite, in-dashboard LLM chat) and their capabilities/limitations.  
7. AI Act: AI Governance & Ethics \- Risk assessment for potential biases or harmful content generation by the integrated LLM chat assistant and prompt refinement tools.  
8. AI Act: Measures to ensure human oversight and control over AI-generated suggestions, especially in the prompt-improvement suite.  
9. AI Act: Clear terms of service regarding ownership and intellectual property of user-generated prompts and content, especially when published to the community.  
10. AI Act Implement clear and accessible terms and conditions for users, including content moderation policies for public prompts.  
11. DSA: Digital Services \- Provide mechanisms for users to report illegal content or content violating terms of service on the public prompt discovery platform.  
12. DSA: Transparency on content moderation decisions and appeal mechanisms for users whose content (e.g., published prompts) is removed or restricted.  
13. DSA: Provide clear information about the ranking parameters for curated, highly-rated prompts on the public homepage.  
14. DSA: Ensure fair and non-discriminatory access to platform features for all users, avoiding self-preferencing if Querino were to become a 'gatekeeper'.  
15. DMA: Interoperability considerations if Querino integrates with or offers services that could be deemed 'core platform services' in the future.

# Core Feature Set

#### **Public Discovery**

A browsable gallery of community-rated prompts sorted by top-rated, trending, newest, and category. Each prompt includes a title, description, Amazon-style star rating, copy button, reviews, and the ability to save it to the user’s library. Authors may publish multiple prompt variants.

#### **Prompt Creation**

A guided multi-step wizard that turns user intent into a polished, framework-based prompt. The wizard gathers information about the user’s goal, domain, tone, constraints, examples, and target LLM. The result is a personalized, structured prompt that can immediately be refined, saved, or published.

#### **Prompt Refinement Tools**

A suite of AI-powered tools that operate on any prompt, offering clarity improvements, structural enhancements, expanded detail, shortening, example generation, step-by-step restructuring, LLM-specific adaptations, debugging help, and side-by-side comparisons. Users may accept, edit, or version the refined result.

#### **Personal Prompt Library**

A private workspace where users store, organize, and manage all prompts, skills, and workflows. The library supports tagging, filtering, search, pinning, editing, version history, collections, publishing controls, AI-powered iteration, and GitHub mirroring for premium users.

### **User Dashboard**

The dashboard functions as a personal command center, showing pinned prompts, recent edits, and quick actions such as launching the Prompt Creation Wizard, opening the refinement tools, or starting a session with the LLM prompt coach. It provides a snapshot of the user’s library, publishing activity, and GitHub sync status where applicable.

### **Data Model**

#### **prompts**

id (uuid), user\_id (uuid), title (text), description (text), content (text), tags (text\[\]), categories (text\[\]), is\_public (boolean), rating\_avg (float), rating\_count (int), created\_at (timestamp), updated\_at (timestamp)

#### **prompt\_versions**

id (uuid), prompt\_id (uuid), version\_number (int), content (text), change\_note (text), created\_at (timestamp)

#### **reviews**

id (uuid), prompt\_id (uuid), user\_id (uuid), stars (int), text (text), created\_at (timestamp)

#### **wizard\_sessions**

Captures multi-step wizard input for generating personalized prompts.

#### **github\_sync**

user\_id (uuid), repo (text), branch (text), sync\_enabled (boolean), last\_synced\_at (timestamp)

# Pricing & Plans

Querino will support three commercial plans: Free, Premium, and Team.

**Free**

* Price: US$0 / month

* Core access to public prompt discovery, ratings, and reviews

* Personal prompt library with a capped number of private prompts

* Limited use of the Prompt Creation Wizard

* Limited access to AI refinement tools

* Limited LLM assistant messages per month

* No GitHub mirroring and no team features

**Premium**

* Target price: US$12 / month

* Unlimited private prompts in the personal library

* Unlimited use of the Prompt Creation Wizard

* Full access to the AI refinement suite

* Full access to the LLM prompt coach in the dashboard

* GitHub mirroring for the user’s library

* Priority publishing and early access to new frameworks

**Team**

* Target price: US$29 per user / month

* Shared team library with role-based access

* Central management of prompts, skills, and workflows for the team

* Team-wide GitHub mirroring configuration

* Multi-seat LLM assistant usage

* Priority support and roadmap input

---

### **Billing & Stripe Integration**

Querino will use Stripe for subscription payments and plan management, with the following design principles:

* Stripe Checkout will be used to start Premium or Team subscriptions.

* Stripe Customer Portal may be used to handle upgrades, downgrades, and cancellations.

* Querino will not rely on Stripe webhooks for core subscription logic. Instead, it will call Stripe’s API directly to validate subscription status when needed.

* On pages or API calls that require Premium or Team features, Querino will:

  * Read the user’s stored plan information.

  * If the plan is Stripe-backed (e.g., “premium-stripe” or “team-stripe”), query Stripe’s API to confirm that the subscription is active.

  * If the plan is complimentary or test-based, skip the Stripe validation and grant access based on local rules.

To avoid excessive Stripe calls, Querino will cache subscription status and last-checked timestamps and only re-validate with Stripe after a configurable interval (for example, every 15 minutes or on explicit plan changes).

---

### **User Roles and Plan Source**

The specification distinguishes between a user’s **entitlements** (what they can access) and the **source** of those entitlements (Stripe or internal).

Each user has:

* A general role for application permissions (e.g., `user`, `admin`).

* A plan type that determines feature entitlements (e.g., `free`, `premium`, `team`).

* A plan source that determines how entitlement is validated (e.g., `stripe`, `gifted`, `test`).

Examples:

* A normal paying user on Premium → `plan_type = premium`, `plan_source = stripe`.

* A manually upgraded “honorary” or gifted Premium user → `plan_type = premium`, `plan_source = gifted`.

* An internal test account → `plan_type = premium`, `plan_source = test`.

For `plan_source = stripe`, Querino validates against Stripe’s API.  
 For `plan_source = gifted` or `plan_source = test`, Querino trusts its own database and does not call Stripe.

---

### **Data Model: Billing Fields on Users**

The `users` table will be extended with billing and entitlement columns.

**users**

* id (uuid) — primary key

* email (text)

* name (text)

* role (text) — `user` or `admin`

* plan\_type (text) — `free`, `premium`, `team`

* plan\_source (text) — `stripe`, `gifted`, `test`

* stripe\_customer\_id (text, nullable) — Stripe customer reference

* stripe\_subscription\_id (text, nullable) — active subscription reference for Premium/Team

* last\_stripe\_check\_at (timestamp, nullable) — last time Stripe status was validated

* stripe\_status\_cache (text, nullable) — cached status, e.g. `active`, `canceled`, `incomplete`

The combination of `plan_type` and `plan_source` will be used by the authorization layer to decide:

* Which features to expose in the UI

* Which API endpoints a user can access

* Whether a Stripe check is required for a given request

---

### **Access Control Logic for Premium and Team Features**

* If `plan_type = free` → only Free features are available.

* If `plan_type IN (premium, team)` and `plan_source IN (gifted, test)` → grant Premium/Team features without calling Stripe.

* If `plan_type IN (premium, team)` and `plan_source = stripe` →

  * If `stripe_status_cache = active` and `last_stripe_check_at` is recent enough → grant access.

  * Otherwise, call Stripe to refresh subscription status, update `stripe_status_cache` and `last_stripe_check_at`, then decide to grant or deny access based on Stripe’s response.

### **Team Accounts and Roles**

Querino supports team-based access for organizations that purchase a Team plan. A team represents a shared workspace with its own prompt library, settings, and billing. Within a team, users have roles that determine what they can do inside that team.

Team roles are separate from individual subscription plans and from the global `role` field on the user (e.g., `user`, `admin`).

The following team roles are defined:

* **Owner**

  * Created automatically for the user who purchases the Team plan.

  * Has full control over the team, including billing, plan changes, and cancellation.

  * Can invite and remove members.

  * Can promote members to Admin or demote them.

  * Can configure team-level integrations (e.g., GitHub mirroring for the team workspace).

* **Admin**

  * Can invite and remove members.

  * Can manage roles for other members (Member ↔ Admin), but cannot change the Owner.

  * Can configure team-level settings (e.g., collections, visibility, publishing defaults, team GitHub folder), except billing.

  * Cannot cancel the subscription or change billing details.

* **Member**

  * Can use all team features that their plan allows (e.g., shared library, wizard, refinement, publishing to team collections).

  * Cannot manage billing or team member roles.

  * Can invite others only if explicitly allowed by a team setting (optional future feature).

Billing for Team is always associated with the team Owner’s Stripe subscription, regardless of how many Admins or Members the team has.

---

# Data Model: Teams and Membership

**teams**

* id (uuid) — primary key

* name (text)

* owner\_id (uuid) — user who controls billing and ultimate team authority

* plan\_type (text) — e.g., `team`

* plan\_source (text) — e.g., `stripe`, `gifted`, `test`

* stripe\_customer\_id (text, nullable)

* stripe\_subscription\_id (text, nullable)

* last\_stripe\_check\_at (timestamp, nullable)

* stripe\_status\_cache (text, nullable) — e.g., `active`, `canceled`

* created\_at (timestamp)

* updated\_at (timestamp)

**team\_members**

* id (uuid) — primary key

* team\_id (uuid) — references `teams.id`

* user\_id (uuid) — references `users.id`

* role (text) — `owner`, `admin`, or `member`

* created\_at (timestamp)

A user can belong to multiple teams, potentially with different roles in each. There is exactly one `owner` per team.

---

### **Team Invitations**

Team invitations can be modeled as a separate table to support inviting users who are not yet registered:

**team\_invitations**

* id (uuid) — primary key

* team\_id (uuid)

* email (text)

* invited\_by\_user\_id (uuid)

* role (text) — intended role (`admin` or `member`)

* token (text) — invitation token

* status (text) — `pending`, `accepted`, `expired`, `revoked`

* created\_at (timestamp)

* expires\_at (timestamp, nullable)

When an invite is accepted, a `team_members` entry is created (or updated if the user was already a member).

---

### **Access Control for Team Features**

* A user can only access a team workspace if there is a `team_members` record linking their `user_id` to the `team_id`.

* Owners and Admins see member management and team settings features.

* Only the Owner can access or modify billing-related pages for that team.

* Team-level features such as shared libraries, publishing to team collections, and team GitHub mirroring are available to all Members, Admins, and the Owner as long as the team’s `plan_type` is `team` and the subscription status (from `stripe_status_cache` or `plan_source`) is valid.

# 

# Technical Architecture

Querino is built as a modern SaaS web application with a clear separation between the user-facing app, the data layer, and the AI/automation layer.

* **Frontend**

  * Built with React (via Lovable), using a clean, responsive UI and Tailwind-style utility classes.

  * Implements the public discovery pages, authentication flows, the logged-in dashboard, the Prompt Creation Wizard UI, the personal library, ratings and reviews, and all management screens.

* **Backend & Data Layer**

  * Supabase is used for authentication, authorization, database storage, and file storage where applicable.

  * The database stores users, prompts, versions, reviews, wizard sessions, billing metadata, and GitHub sync configuration.

  * Light API routes (or server actions) in the app are responsible for:

    * Reading and writing data in Supabase

    * Enforcing access control and plan limits

    * Coordinating calls to the AI & automation layer (n8n)

* **AI & Automation Layer (n8n)**

  * n8n acts as an external workflow engine and AI orchestration layer.

  * The app calls n8n via authenticated webhooks or HTTP nodes for any operation that requires LLMs or more complex background processing.

  * n8n workflows encapsulate all interactions with AI providers (e.g., OpenAI, Anthropic) and selected third-party APIs (e.g., GitHub, email providers), so the core Querino app remains simple and focused on product logic.

This architecture allows Querino to evolve quickly: new AI functions or integrations can be added by introducing or modifying n8n workflows, while the main app only needs to send and receive structured payloads.

---

### **AI & Automation Layer (n8n)**

Querino uses n8n as a dedicated AI and automation layer. All AI-powered features and selected background tasks are implemented as n8n workflows. The Querino app communicates with these workflows via secure HTTP endpoints.

Typical responsibilities of n8n include:

* **Prompt Refinement Suite**

  * Receive a prompt and a requested transformation (e.g., improve clarity, expand detail, shorten, add examples, debug).

  * Call the appropriate LLM with a system prompt and the user’s content.

  * Return refined prompt suggestions, optional explanations, and any metadata back to the app.

* **Prompt Creation Wizard Logic**

  * Receive wizard input (goal, context, tone, constraints, examples, target LLM).

  * Generate one or more prompt candidates based on predefined frameworks.

  * Optionally generate variants (e.g., “concise”, “detailed”, “step-by-step”).

* **LLM Prompt Coach (Dashboard Chat)**

  * Handle conversational interactions between the user and the in-dashboard assistant.

  * Maintain minimal conversation context (e.g., last messages, referenced prompt IDs) while respecting privacy and plan limits.

  * Provide explanations, debugging help, and improvement suggestions for prompts.

* **Rating- and Discovery-Related Enhancements** (future)

  * Periodically enrich prompt entries with AI-generated summaries, tags, or categories.

  * Suggest related prompts or collections based on content similarity.

* **GitHub Sync and Other Background Tasks (future)**

  * Execute GitHub sync jobs for premium users based on their `github_sync` configuration.

  * Create or update files in the configured repository and folder, create commits, and push changes.

  * Send notification emails or in-app messages when long-running jobs complete or fail.

Each n8n workflow exposes a clearly defined input and output schema so that the Querino app can treat these workflows as external services. Errors from n8n are surfaced back to the user where appropriate and logged for debugging and observability.

---

### **Integration Pattern Between App and n8n**

* The Querino app calls n8n via secured HTTP endpoints whenever an AI operation or background process is needed (e.g., “refine this prompt”, “run the wizard with these inputs”, “answer this coaching question”).

* Payloads include the minimum necessary data: user ID (or session token), prompt content or wizard inputs, requested operation, and any configuration flags.

* n8n returns structured JSON responses containing refined prompt text, suggested variants, explanations, or job status.

* For synchronous tasks (e.g., refinement, wizard output), the app waits for the n8n response and updates the UI immediately.

* For asynchronous tasks (e.g., GitHub sync), the app may poll a status endpoint or rely on a status field stored in Supabase and updated by n8n.

This integration strategy allows Querino to centralize AI and automation logic in n8n while keeping the main application codebase lean, testable, and focused on UX, data, and access control.

# SEO & Public Prompt Pages

Public prompts in Querino are intended to be discoverable through search engines. Any prompt that a user explicitly marks as public should be rendered on its own dedicated, indexable page with a stable URL.

Each public prompt page should:

* Be accessible without authentication.

* Have a human-readable URL including a slug, e.g. `/prompts/<id>/<slug>` (for example, `/prompts/abc123/summarize-zendesk-tickets`).

* Include semantic HTML structure for title, description, rating, tags, author, and (optionally) example input and example output.

* Expose appropriate metadata for SEO (HTML `<title>`, `<meta>` description) and social sharing (Open Graph and Twitter Cards).

* Be included in a sitemap that is regularly updated so search engines can discover new public prompts.

* Be allowed in `robots.txt` so they can be crawled and indexed, unless a prompt has been unpublished.

When a user unpublishes a prompt, its public page must either be removed or return a suitable status (e.g. 404 or 410\) and be excluded from future sitemap updates.

Only public prompts are indexable. Private prompts and any dashboard content remain behind authentication and are not exposed to search engines.

# Usage Limits

### **Monthly LLM Usage Caps**

Querino enforces global usage caps to prevent excessive consumption of LLM resources.

**Free Plan**

* Wizard runs: **20 / month**

* Refinement operations: **50 / month**

* LLM assistant messages: **50 / month**

* Maximum tokens consumed (sum of prompt \+ completion): **50,000 tokens / month**

**Premium Plan**

* Wizard runs: **5,000 / month**

* Refinement operations: **5,000 / month**

* LLM assistant messages: **5,000 / month**

* Maximum combined tokens consumed: **300,000 tokens / month**

**Team Plan**  
 (Limits applied *per seat*, unless otherwise configured by the team owner.)

* Wizard runs: **10,000 / month**

* Refinement operations: **10,000 / month**

* LLM assistant messages: **10,000 / month**

* Maximum combined tokens consumed: **1,000,000 tokens / month per seat**

All usage counters reset on the user’s monthly billing cycle date.

If a user reaches any cap, Querino must:

* Deny further LLM requests for that category until reset, and

* Display a message indicating which limit has been reached.

Team owners may optionally purchase additional token packs (future feature).

---

## **Prompt Storage Limits**

**Free Plan**

* Maximum private prompts: **25**

* Maximum collections: **3**

**Premium Plan**

* Unlimited private prompts

* Unlimited collections

**Team Plan**

* Unlimited team prompts

* Unlimited team collections

* Per-seat limits apply to personal libraries as above

---

# Feature Access Matrix

### **Legend**

* **Yes** \= full access

* **Limited** \= capped by monthly usage limits

* **No** \= feature unavailable

| Feature | Free User | Premium User | Team Owner | Team Admin | Team Member |
| ----- | ----- | ----- | ----- | ----- | ----- |
| Browse public prompts | Yes | Yes | Yes | Yes | Yes |
| Rate & review prompts | Yes | Yes | Yes | Yes | Yes |
| Save prompts to library | Yes (max 25\) | Yes | Yes | Yes | Yes |
| Prompt Creation Wizard | Limited | Yes | Yes | Yes | Yes |
| Refinement tools | Limited | Yes | Yes | Yes | Yes |
| LLM prompt coach | Limited | Yes | Yes | Yes | Yes |
| Version history | Yes | Yes | Yes | Yes | Yes |
| Publish prompts | Yes | Yes | Yes | Yes | Yes |
| Team library access | No | No | Yes | Yes | Yes |
| Team management | No | No | Yes | Yes | No |
| Billing management | No | No | Yes | No | No |
| GitHub sync (personal) | No | Yes | Optional | Optional | No |
| GitHub sync (team) | No | No | Yes | Yes | No |
| Configure team folder path | No | No | Yes | Yes | No |

---

# State Transitions

### **Stripe Subscription States**

Querino tracks subscription state using `stripe_status_cache`. Valid states:

* `active`

* `past_due`

* `unpaid`

* `canceled`

* `incomplete`

* `incomplete_expired`

* `trialing`

* `paused` (if supported by Stripe)

**State transition handling:**

* When transitioning to `canceled`, `incomplete_expired`, or `unpaid`, limit access to Free features immediately.

* When transitioning to `active` or `trialing`, restore Premium or Team features.

* Querino retries validation if Stripe returns a temporary network error.

* Querino does not change `plan_type` automatically; only entitlement changes.

* For `plan_source = gifted` or `plan_source = test`, subscription state is ignored.

---

# Team Invitation States

Team invitations move through these states:

* `pending`

* `accepted`

* `expired`

* `revoked`

**Rules:**

* `pending → accepted` when the invited email completes signup or logs in.

* `pending → expired` after configured expiration time.

* `pending → revoked` when the inviter cancels.

* Accepted invitations create or update a row in `team_members`.

---

# GitHub Sync State Rules

GitHub sync uses `last_sync_status`:

* `disabled`

* `pending`

* `success`

* `failed`

**Rules:**

* When sync is enabled, state becomes `pending` until the next completed job.

* On successful sync, set `success` and update `last_synced_at` and `last_synced_commit_sha`.

* On failure (push, commit, auth, or folder errors), set `failed` and populate `last_sync_error`.

* Querino never modifies files outside the configured `folder_path`.

* Re-enabling sync resets state to `pending`.

---

# Error Handling Requirements

### **AI / n8n Errors**

If any AI pipeline (wizard, refinement, LLM coach) fails:

* Do not overwrite or modify user content.

* Return a descriptive error message to the UI.

* Log failure with workflow ID, payload size, and error code.

* If failure is due to token limits, link the user to the pricing page.

### **Stripe API Errors**

If Stripe returns a network error:

* Do not downgrade user plan.

* Treat the entitlement as “temporarily unverified”.

* Re-check Stripe at next interaction requiring validation.

### **GitHub Sync Errors**

If writing, committing, or pushing fails:

* Keep local prompt and version history intact.

* Mark sync status as `failed`.

* Do not retry automatically more than once per hour.

### **Library Quota Errors**

If user attempts to exceed max private prompts:

* Prevent creation

* Display: “Free plan allows up to 25 private prompts. Upgrade to Premium for unlimited storage.”

### **Usage Limit Errors**

If user reaches an LLM quota:

* Deny operation

* Return message: “You’ve reached your monthly {wizard/refinement/chat} limit. Limits reset on {date}.”

---

## **“Done When…” Acceptance Criteria for Core Flows**

### **Prompt Creation Wizard**

* Wizard input stored in `wizard_sessions`

* Prompt generated by AI workflow

* Prompt saved in `prompts` table

* Initial version saved in `prompt_versions`

* Appears immediately in the user’s library

* LLM usage count increments

* If pinned: appears in dashboard pins

### **Prompt Refinement**

* Original content preserved

* Refined output returned from AI workflow

* User can save as new version

* Version record created

* Usage count increments

### **Publishing**

* `is_public = true`

* Public prompt page generated with slug

* Appears in discovery feed

* Included in sitemap

* Search engines allowed to index

* Unpublishing removes from sitemap and marks as non-indexable

### **Team Management**

* Owner/Admin can invite or remove members

* Member roles update correctly in `team_members`

* Billing pages visible only to Owner

* Shared team library visible to all team members

* Team GitHub folder path used for sync jobs

# Test users

1. Free user: Fred

   * Email: **fred@free.com**

   * Password: **Dell@123**

   * App role: **user**

   * Plan type: **free**

   * Plan source: **test**

   * Team membership: **none**

2. Pro user (individual Premium): Peter

   * Email: **peter@pro.com**

   * Password: **Dell@123**

   * App role: **user**

   * Plan type: **premium**

   * Plan source: **test**

   * Purpose: tests full Premium features without Stripe checks (gifted/test premium).

3. Business user (Stripe-backed Premium): Benny

   * Email: **benny@business.com**

   * Password: **Dell@123**

   * App role: **user**

   * Plan type: **premium**

   * Plan source: **stripe**

   * stripe\_customer\_id / stripe\_subscription\_id: **dummy but non-null** in test data

   * Purpose: tests flows where Premium is validated against Stripe.

4. Global admin user: Alice

   * Email: **alice@admin.com**

   * Password: **Dell@123**

   * App role: **admin**

   * Plan type: **premium**

   * Plan source: **test**

   * Team membership: can be added as owner or admin to any test team as needed.

5. Team owner (Team plan): Tina

   * Email: **tina@teamowner.com**

   * Password: **Dell@123**

   * App role: **user**

   * Personal plan type: **free**

   * Personal plan source: **test**

   * Team membership:

     * Team: **“Acme AI Studio (Test Team 1)”**

     * Team role: **owner**

   * Team record for “Acme AI Studio (Test Team 1)” has:

     * plan\_type: **team**

     * plan\_source: **test**

6. Team admin: Andy

   * Email: **andy@teamadmin.com**

   * Password: **Dell@123**

   * App role: **user**

   * Personal plan type: **free**

   * Personal plan source: **test**

   * Team membership:

     * Team: **“Acme AI Studio (Test Team 1)”**

     * Team role: **admin**

7. Team member: Mia

   * Email: **mia@teammember.com**

   * Password: **Dell@123**

   * App role: **user**

   * Personal plan type: **free**

   * Personal plan source: **test**

   * Team membership:

     * Team: **“Acme AI Studio (Test Team 1)”**

     * Team role: **member**

8. Gifted Premium (non-Stripe) user: Grace

   * Email: **grace@gifted.com**

   * Password: **Dell@123**

   * App role: **user**

   * Plan type: **premium**

   * Plan source: **gifted**

   * Purpose: tests gifted/complimentary premium where Stripe is never called.

# Test Cases

Test cases for the agentic development of Querina shall be written and maintained in the file pending\_tests.json in the following format:

\[

  {

    "id": "FEAT-01",

    "category": "Authentication",

    "description": "User cannot login with invalid credentials",

    "priority": "high",

    "steps": \[

      "Navigate to login page",

      "Enter 'user@example.com' as email",

      "Enter 'wrongpassword' as password",

      "Click 'Sign In' button",

      "Check for error message containing 'Invalid credentials'"

    \],

    "passes": false

  },

  {

    "id": "FEAT-02",

    "category": "Dashboard",

    "description": "Dashboard shows user name after login",

    "priority": "medium",

    "steps": \[

      "Login with valid credentials",

      "Wait for redirect to /dashboard",

      "Verify text 'Welcome, User' is visible in header"

    \],

    "passes": false

  }

\]

U• Blended public discovery and private creation studio

* • AI-powered prompt improvement tools  
* • Integrated LLM chat assistant for refinement and debugging  
* • GitHub mirroring for version control (premium feature)  
* • Unified interface for prompts, Claude skills, and workflow